{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import datetime as dt\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop inconsistent columns across chunks\n",
    "featuresToDrop = [\"hits_transaction.localTransactionRevenue\",\n",
    "                      \"hits_transaction.localTransactionShipping\",\n",
    "                      \"hits_transaction.localTransactionTax\",\n",
    "                      \"hits_transaction.transactionId\",\n",
    "                      \"hits_transaction.transactionRevenue\",\n",
    "                      \"hits_item.transactionId\",\n",
    "                      \"hits_transaction.transactionShipping\",\n",
    "                      \"hits_transaction.transactionTax\",\n",
    "                      \"hits_transaction.affiliation\"]\n",
    "csvs = [5,7, 11, 12, 13, 14]\n",
    "for i in csvs:\n",
    "    train_df = pd.read_csv(\"flatten_train_part_\"+str(i-1)+\".csv\",dtype={'fullVisitorId': 'str'})\n",
    "    train_df = train_df.drop(featuresToDrop,axis = 1)\n",
    "    train_df.to_csv(\"flatten_train_part_\"+str(i-1)+\".csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop inconsistent column in chunk1\n",
    "train_df = pd.read_csv(\"flatten_train_part_1.csv\",dtype={'fullVisitorId': 'str'})\n",
    "train_df = train_df.drop([\"trafficSource_campaignCode\"],axis = 1)\n",
    "train_df.to_csv(\"flatten_train_part_1.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add missing column in chunk5\n",
    "train_df = pd.read_csv(\"flatten_train_part_5.csv\",dtype={'fullVisitorId': 'str'})\n",
    "train_df[\"hits_latencyTracking.redirectionTime\"] = np.nan\n",
    "train_df.to_csv(\"flatten_train_part_5.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add missing columns in chunk12\n",
    "train_df = pd.read_csv(\"flatten_train_part_12.csv\",dtype={'fullVisitorId': 'str'})\n",
    "train_df[\"hits_latencyTracking.serverConnectionTime\"] = np.nan\n",
    "train_df[\"hits_latencyTracking.domainLookupTime\"] = np.nan\n",
    "train_df.to_csv(\"flatten_train_part_12.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add missing column in chunk13\n",
    "train_df = pd.read_csv(\"flatten_train_part_13.csv\",dtype={'fullVisitorId': 'str'})\n",
    "train_df[\"hits_latencyTracking.domainLookupTime\"] = np.nan\n",
    "train_df.to_csv(\"flatten_train_part_13.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop constant columns from all chunks\n",
    "#drop 'hits_social.socialInteractionNetworkAction' - has only : and unknown\n",
    "#drop trafficSource_adwordsClickInfo_targetingCriteria - has only {} and unknown\n",
    "for i in range(0,16):\n",
    "    train_df = pd.read_csv(\"flatten_train_part_\"+str(i)+\".csv\",dtype={'fullVisitorId': 'str'})\n",
    "    na_vals = ['unknown.unknown', '(not set)', 'not available in demo dataset',\n",
    "               '(not provided)', '(none)', '<NA>']\n",
    "    train_df = train_df.replace(na_vals, np.nan, regex=True)\n",
    "    for column in train_df.columns:\n",
    "        if train_df[column].dtype == np.int64 : \n",
    "            train_df[column].fillna(0, inplace=True)\n",
    "        elif train_df[column].dtype == np.float64 : \n",
    "            train_df[column].fillna(0.0, inplace=True)\n",
    "        elif train_df[column].dtype == np.bool : \n",
    "            train_df[column].fillna(False, inplace=True)\n",
    "        else:\n",
    "            train_df[column].fillna(\"Unknown\", inplace=True)\n",
    "    #index column for value. We are interested in value so drop it.\n",
    "    featuresToDrop = [\"customDimensions_index\"]\n",
    "    train_df = train_df.drop(featuresToDrop,axis = 1)\n",
    "    constant_columns = [column for column in train_df.columns if train_df[column].nunique() == 1]\n",
    "    constant_columns.append(\"trafficSource_adwordsClickInfo_targetingCriteria\")\n",
    "    constant_columns.append(\"hits_social.socialInteractionNetworkAction\")\n",
    "    train_df = train_df.drop(constant_columns,axis = 1)\n",
    "    train_df.to_csv(\"preprocess_train_part_\"+str(i)+\".csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify all chunks have same features\n",
    "for i in range(0,16):\n",
    "    train_df = pd.read_csv(\"preprocess_train_part_\"+str(i)+\".csv\",dtype={'fullVisitorId': 'str'})\n",
    "    print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resolve mixed types\n",
    "for i in range(0,16):\n",
    "    train_df = pd.read_csv(\"preprocess_train_part_\"+str(i)+\".csv\",\n",
    "                           dtype={'fullVisitorId': 'str',\n",
    "                                  'date':'str',\n",
    "                                  'visitStartTime':'str',\n",
    "                                  'device_isMobile':'str',\n",
    "                                  'hits_exceptionInfo.isFatal':'str',\n",
    "                                  'hits_isInteraction':'str',\n",
    "                                  'hits_isEntrance':'str',\n",
    "                                  'hits_isExit':'str'\n",
    "                                 })\n",
    "    #replace USD with nan and fill nan for visitNumber field\n",
    "    na_vals = ['USD']\n",
    "    train_df.visitNumber.replace(na_vals, np.nan, inplace=True)\n",
    "    train_df.visitNumber.fillna(0, inplace=True)\n",
    "    #replace No with nan and fill nan for date field\n",
    "    na_vals = ['No']\n",
    "    train_df.date.replace(na_vals, np.nan, inplace=True)\n",
    "    train_df.date.fillna(\"Unknown\", inplace=True)\n",
    "    #read them in read_csv\n",
    "    mixedColumnsToStr = ['date','visitStartTime','device_isMobile','hits_exceptionInfo.isFatal','hits_isInteraction','hits_isEntrance','hits_isExit']\n",
    "    mixedColumnsToNumeric = ['visitNumber']\n",
    "    for column in mixedColumnsToNumeric:\n",
    "        train_df[column] = pd.to_numeric(train_df[column])\n",
    "    train_df.to_csv(\"no_mixed_train_part_\"+str(i)+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate chunks into single file\n",
    "concat_df = pd.read_csv(\"no_mixed_train_part_\"+str(0)+\".csv\",\n",
    "                           dtype={'fullVisitorId': 'str',\n",
    "                                  'date':'str',\n",
    "                                  'visitStartTime':'str',\n",
    "                                  'device_isMobile':'str',\n",
    "                                  'hits_exceptionInfo.isFatal':'str',\n",
    "                                  'hits_isInteraction':'str',\n",
    "                                  'hits_isEntrance':'str',\n",
    "                                  'hits_isExit':'str'\n",
    "                                 })\n",
    "for i in range(1,16):\n",
    "    train_df = pd.read_csv(\"no_mixed_train_part_\"+str(i)+\".csv\",\n",
    "                           dtype={'fullVisitorId': 'str',\n",
    "                                  'date':'str',\n",
    "                                  'visitStartTime':'str',\n",
    "                                  'device_isMobile':'str',\n",
    "                                  'hits_exceptionInfo.isFatal':'str',\n",
    "                                  'hits_isInteraction':'str',\n",
    "                                  'hits_isEntrance':'str',\n",
    "                                  'hits_isExit':'str'\n",
    "                                 })\n",
    "    concat_df = pd.concat([concat_df, train_df], ignore_index=True)\n",
    "concat_df.to_csv(\"whole.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to label encode string features\n",
    "def preprocess(X,labelColumn,nonCategoryColumns):\n",
    "        nonNullData = X\n",
    "        dataWithoutClass = nonNullData.iloc[:,nonNullData.columns != labelColumn ]\n",
    "        classDf = nonNullData.iloc[:, nonNullData.columns==labelColumn]       \n",
    "        \n",
    "        stringColumnsIncl = dataWithoutClass.select_dtypes(exclude=['number','bool']).columns \n",
    "        stringColumns = []\n",
    "        for column in stringColumnsIncl:\n",
    "            if column not in nonCategoryColumns:\n",
    "                stringColumns.append(column)\n",
    "        numericColumns = dataWithoutClass.select_dtypes(include=['number','bool']).columns  \n",
    "        labeledData = nonNullData\n",
    "        labeledDataWithoutClass = dataWithoutClass\n",
    "       \n",
    "        if(len(stringColumns)!=0):\n",
    "            if(len(stringColumns)==len(dataWithoutClass.columns)):                \n",
    "                labeledDataWithoutClass = dataWithoutClass.apply(preprocessing.LabelEncoder().fit_transform)\n",
    "            else:\n",
    "                labeledDataWithoutClass = pd.concat([dataWithoutClass[numericColumns],dataWithoutClass[nonCategoryColumns],dataWithoutClass[stringColumns].apply(preprocessing.LabelEncoder().fit_transform)],axis=1)\n",
    "        labeledData = pd.concat([labeledDataWithoutClass,nonNullData.iloc[:, nonNullData.columns==labelColumn]],axis=1)\n",
    "        \n",
    "        return labeledData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode features\n",
    "train_df = pd.read_csv(\"whole.csv\",\n",
    "                       dtype={'fullVisitorId': 'str',\n",
    "                              'date':'str',\n",
    "                              'visitStartTime':'str',\n",
    "                              'device_isMobile':'str',\n",
    "                              'hits_exceptionInfo.isFatal':'str',\n",
    "                              'hits_isInteraction':'str',\n",
    "                              'hits_isEntrance':'str',\n",
    "                              'hits_isExit':'str'\n",
    "                             })\n",
    "labelColumn = \"totals_transactionRevenue\"\n",
    "nonCategoryColumns = [\"date\",\"fullVisitorId\",\"geoNetwork_networkDomain\",\"hits_appInfo.exitScreenName\",\"hits_appInfo.landingScreenName\",\"hits_appInfo.screenName\",\"hits_eventInfo.eventLabel\",\"hits_page.pagePath\",\"hits_page.pagePathLevel1\",\"hits_page.pagePathLevel2\",\"hits_page.pagePathLevel3\",\"hits_page.pagePathLevel4\",\"hits_page.pageTitle\",\"hits_referer\",\"trafficSource_adContent\",\"trafficSource_adwordsClickInfo_gclId\",\"trafficSource_campaign\",\"trafficSource_keyword\",\"trafficSource_referralPath\",\"visitStartTime\"]\n",
    "train_df = preprocess(train_df,labelColumn,nonCategoryColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find correlation\n",
    "\n",
    "corr_df = train_df.corr()\n",
    "\n",
    "plt.imshow(corr_df.values)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop correlated columns\n",
    "correlatedColumnsToDrop = [\"hits_contentGroup.previousContentGroup1\",\"hits_contentGroup.previousContentGroup2\",\n",
    "\"hits_contentGroup.previousContentGroup3\",\"hits_contentGroup.previousContentGroup4\",\n",
    "\"hits_contentGroup.previousContentGroup5\",\"hits_social.socialInteractionNetworkAction\",\n",
    "\"hits_contentGroup.contentGroupUniqueViews1\",\"hits_contentGroup.contentGroupUniqueViews2\",\n",
    "\"totals_pageviews\",\"trafficSource_adwordsClickInfo_page\",\"trafficSource_adwordsClickInfo_adNetworkType\",\n",
    "\"trafficSource_adwordsClickInfo_slot\",\"hits_latencyTracking.domContentLoadedTime\",\"hits_eventInfo.eventAction\",\"hits_type\",\n",
    "\"hits_contentGroup.contentGroup2\",\"hits_transaction.currencyCode\"]\n",
    "train_df = train_df.drop(correlatedColumnsToDrop,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hits_page.pageTitle gives info about the page which is an aggregation of all pagePaths\n",
    "#trafficSource_referralPath can be removed asits info is covered in trafficSource_source\n",
    "#screen name and landing screen name are same\n",
    "#trafficSource_adwordsClickInfo_gclId - not required as its googleCLickId\n",
    "manualColumnsToDrop = [\"hits_page.pagePath\",\"hits_page.pagePathLevel1\",\"hits_page.pagePathLevel2\",\"hits_page.pagePathLevel3\",\"hits_page.pagePathLevel4\",\"trafficSource_referralPath\",\"hits_appInfo.screenName\",\"trafficSource_adwordsClickInfo_gclId\"]\n",
    "train_df = train_df.drop(manualColumnsToDrop,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process date field\n",
    "\n",
    "def processDate(date):\n",
    "    if date.lower() == 'unknown':\n",
    "        return np.nan\n",
    "    else:\n",
    "        return dt.datetime.strptime(str(date), '%Y%m%d')\n",
    "train_df[\"date_datetime\"] = train_df['date'].apply(processDate)\n",
    "train_df = train_df.dropna()\n",
    "train_df['date_year'] = train_df['date_datetime'].dt.year\n",
    "train_df['date_month'] = train_df['date_datetime'].dt.month\n",
    "train_df['date_day'] = train_df['date_datetime'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process visitStartTime field\n",
    "\n",
    "def convertPosixToDate(epoch):   \n",
    "    if(epoch.isdigit()):\n",
    "        return dt.datetime.utcfromtimestamp(int(epoch))\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def categorizeHour(hour):\n",
    "    if hour >= 0.0 and hour < 4.0:\n",
    "        return \"midnight\"\n",
    "    if hour >= 4.0 and hour < 6.0:\n",
    "        return \"earlyMorning\"\n",
    "    if hour >= 6.0 and hour < 12.0:\n",
    "        return \"morning\"\n",
    "    if hour >= 12.0 and hour < 16.0:\n",
    "        return \"afternoon\"\n",
    "    if hour >= 16.0 and hour < 19.0:\n",
    "        return \"evening\"\n",
    "    if hour >= 19.0 and hour < 0.0:\n",
    "        return \"night\"\n",
    "\n",
    "train_df['visitStartTime_date'] = train_df['visitStartTime'].apply(convertPosixToDate)\n",
    "train_df = train_df.dropna()\n",
    "train_df['visitStartTime_year'] = train_df['visitStartTime_date'].dt.year\n",
    "train_df['visitStartTime_month'] = train_df['visitStartTime_date'].dt.month\n",
    "train_df['visitStartTime_day'] = train_df['visitStartTime_date'].dt.day\n",
    "train_df['visitStartTime_hour'] = train_df['visitStartTime_date'].dt.hour\n",
    "\n",
    "\n",
    "    \n",
    "train_df[\"visitStartTime_hour\"] = train_df['visitStartTime_hour'].apply(categorizeHour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the date columns that we processed\n",
    "columnsToDrop = [\"visitStartTime\",\"visitStartTime_date\",\"date\",\"date_datetime\"]\n",
    "train_df = train_df.drop(columnsToDrop,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are interested only in the host name\n",
    "\n",
    "def hostName(url):\n",
    "    return urlparse(url).hostname\n",
    "train_df['hits_referer'] = train_df['hits_referer'].apply(hostName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check whether the landing page is the same as exit page\n",
    "train_df[\"isEntryExitSame\"] = train_df[\"hits_appInfo.landingScreenName\"] == train_df[\"hits_appInfo.exitScreenName\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handle null, nan\n",
    "for column in train_df.columns:\n",
    "    if train_df[column].dtype == np.int64 : \n",
    "        train_df[column].fillna(0, inplace=False)\n",
    "    elif train_df[column].dtype == np.float64 : \n",
    "        train_df[column].fillna(0.0, inplace=False)\n",
    "    elif train_df[column].dtype == np.bool : \n",
    "        train_df[column].fillna(False, inplace=False)\n",
    "    else:\n",
    "        train_df[column].fillna(\"Unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode category features\n",
    "labelColumn = \"totals_transactionRevenue\"\n",
    "nonCategoryColumns = [\"fullVisitorId\"]\n",
    "label_df = preprocess(train_df,labelColumn,nonCategoryColumns)\n",
    "label_df.to_csv(\"finalEncodedData.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
