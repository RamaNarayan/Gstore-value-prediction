{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Project_Train.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "7R05SGPVDEsE",
        "colab_type": "code",
        "outputId": "5800a788-0520-40f7-92d8-ebb3f0c404d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "cell_type": "code",
      "source": [
        "########## Install scikit-learn ##########\n",
        "\n",
        "# !pip uninstall scikit-learn -y\n",
        "# !pip install Cython\n",
        "# !pip install git+git://github.com/scikit-learn/scikit-learn.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling scikit-learn-0.19.2:\n",
            "  Successfully uninstalled scikit-learn-0.19.2\n",
            "Collecting Cython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/e0/0592be5b851c8013aa253592606ca265862d27444d908e029fd75d563c9c/Cython-0.29.1-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.1MB 8.2MB/s \n",
            "\u001b[?25hInstalling collected packages: Cython\n",
            "Successfully installed Cython-0.29.1\n",
            "Collecting git+git://github.com/scikit-learn/scikit-learn.git\n",
            "  Cloning git://github.com/scikit-learn/scikit-learn.git to /tmp/pip-req-build-n7ob7fzb\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.dev0) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.dev0) (1.1.0)\n",
            "Building wheels for collected packages: scikit-learn\n",
            "  Running setup.py bdist_wheel for scikit-learn ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-8zlnb2q2/wheels/a1/50/0e/316ef2ff8d4cfade292bd20b49efda94727688a153382745a6\n",
            "Successfully built scikit-learn\n",
            "Installing collected packages: scikit-learn\n",
            "Successfully installed scikit-learn-0.21.dev0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FntkcNoqDRy8",
        "colab_type": "code",
        "outputId": "89feaa52-f851-47c7-c985-6507f661a52e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "cell_type": "code",
      "source": [
        "########## Install Microsoft Light GBM ##########\n",
        "\n",
        "# !pip install lightgbm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lightgbm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/3b/4ae113193b4ee01387ed76d5eea32788aec0589df9ae7378a8b7443eaa8b/lightgbm-2.2.2-py2.py3-none-manylinux1_x86_64.whl (1.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.2MB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.21.dev0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.14.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.1.0)\n",
            "Installing collected packages: lightgbm\n",
            "Successfully installed lightgbm-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qKvuDv99DTW9",
        "colab_type": "code",
        "outputId": "9dd6e442-ccff-4a9c-b211-6fa6ca11e28d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "########## Install XGBoost ##########\n",
        "\n",
        "# !pip install xgboost"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.7.post4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.14.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hSrqeEWaDUyA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "########## Import libraries ##########\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import sklearn.metrics as sklm\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LaAXX_0RDhKP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "########## Scaling of data ##########\n",
        "\n",
        "def scaledData(data):\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(data)\n",
        "    scaledData = scaler.transform(data)\n",
        "    return scaledData"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FNqCF7trEJKj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "########## Finding Principal Components of X_train ##########\n",
        "\n",
        "def compute_PCA(X):\n",
        "  pca = PCA(n_components=50)\n",
        "  X_pca = pca.fit_transform(X)\n",
        "  return X_pca\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kWgkBca1D1nF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "########## Load csv and prepara the datasets ########## \n",
        "\n",
        "def load(csv_path):\n",
        "    df = pd.read_csv(csv_path,dtype={'fullVisitorId': 'str'})\n",
        "    labelColumn = \"totals_transactionRevenue\"\n",
        "    y_data = df[labelColumn]\n",
        "    X_data = df.drop(['fullVisitorId', labelColumn],axis = 1)\n",
        "    y = np.log1p(y_data.values)\n",
        "    X = scaledData(X_data)\n",
        "    #X = compute_PCA(X)      # Un-comment for PCA \n",
        "    return df, X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6a9Jmj_XEuSL",
        "colab_type": "code",
        "outputId": "5ef0bb26-978b-4aa2-ad8b-ecdd62a676fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "########## Load Whole Training Data ##########\n",
        "\n",
        "train_df, X, y = load(\"finalEncodedData.csv\") \n",
        "\n",
        "########## Load 10% Training Sample data for faster training ########## \n",
        "########## Run only once if comparing different algorithms and configurations ##########\n",
        "\n",
        "# train_df = train_df.sample(180000) "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by StandardScaler.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "b3Su0y2tE6G0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "########## Gradient Boosting Regressor  ##########\n",
        "\n",
        "#-----#-----#----- With Default Parameters #-----#-----#-----\n",
        "\n",
        "estimator = GradientBoostingRegressor()      \n",
        "\n",
        "#-----#-----#-----For Parameter tuning #-----#-----#-----\n",
        "\n",
        "# tuned_parameters = [ { 'loss': ['ls', 'lad'], 'learning_rate': [0.01,0.1], 'n_estimators':[100,300], 'max_depth': [3,5]} ] \n",
        "\n",
        "#-----#-----#----- Custom Parameter Run #-----#-----#-----\n",
        "\n",
        "# estimator = GradientBoostingRegressor(n_estimators=1000,learning_rate=0.01, max_depth=5) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DwajP6KUHZud",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "########## Random Forest Regressor ##########\n",
        "\n",
        "#-----#-----#----- With Default Parameters #-----#-----#-----\n",
        "\n",
        "# estimator = RandomForestRegressor()\n",
        "\n",
        "#-----#-----#-----For Parameter tuning #-----#-----#-----\n",
        "\n",
        "# tuned_parameters = [ {'max_features': [\"auto\", \"sqrt\"], 'warm_start': [True, False], 'n_estimators':[400,800], 'max_depth': [10,20]} ]\n",
        "\n",
        "#-----#-----#----- Custom Parameter Run #-----#-----#-----\n",
        "\n",
        "# estimator = RandomForestRegressor(n_estimators=1000, max_depth=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n-Hs_o4SICXH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "########## AdaBoost Regressor ##########\n",
        "\n",
        "#-----#-----#----- With Default Parameters #-----#-----#-----\n",
        "\n",
        "# estimator = AdaBoostRegressor()\n",
        "\n",
        "#-----#-----#----- For Parameter tuning #-----#-----#-----\n",
        "\n",
        "# tuned_parameters = [ {'loss':['linear', 'square'], 'learning_rate': [0.01, 0.1, 1.0], 'n_estimators':[100,300], 'random_state': [None,42]} ]\n",
        "\n",
        "#-----#-----#----- Custom Parameter Run #-----#-----#-----\n",
        "\n",
        "# estimator = AdaBoostRegressor(learning_rate = 1.0, n_estimators = 50)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2rF8XloyI4__",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "########## Microsoft Light GBM Regressor ##########\n",
        "\n",
        "#-----#-----#----- With Default Parameters #-----#-----#-----\n",
        "\n",
        "# estimator = lgb.LGBMRegressor()\n",
        "\n",
        "#-----#-----#-----For Cross Validation Folds #-----#-----#-----\n",
        "\n",
        "# lgtrain = lgb.Dataset(X,y)\n",
        "\n",
        "# lgbm_params =  { 'boosting_type': 'gbdt', 'objective': 'regression', 'metric': 'rmse', 'n_jobs':-1, \"learning_rate\": 0.05,\"num_leaves\": 31, \"max_depth\": 5, \"reg_alpha\": 0.05, \"reg_lambda\": 0.1 }\n",
        "\n",
        "# lgb_cv = lgb.cv(params = lgbm_params, train_set = lgtrain, num_boost_round = 1500, stratified=False, nfold = 5, verbose_eval = 100, seed = 42, early_stopping_rounds = 50)\n",
        "\n",
        "# optimal_rounds = np.argmin(lgb_cv['rmse-mean'])\n",
        "\n",
        "# best_cv_score = min(lgb_cv['rmse-mean'])\n",
        "\n",
        "# print(\"optimal rounds\",optimal_rounds)\n",
        "# print(\"best_cv_score\",best_cv_score)\n",
        "\n",
        "# estimator = lgb.train(params = lgbm_params, train_set = lgtrain, num_boost_round = optimal_rounds + 1, verbose_eval = 50)\n",
        "\n",
        "#-----#-----#----- Custom Parameter Run #-----#-----#-----\n",
        "\n",
        "# estimator = lgb.LGBMRegressor(boosting_type='dart', num_leaves=28, max_depth=5, learning_rate=0.1, n_estimators=10000, bagging_freq = 50, feature_fraction = 0.5, reg_alpha=0.01, reg_lambda=0.01, bagging_fraction = 0.5, n_jobs = -1, metric= 'rmse')\n",
        "\n",
        "# estimator = lgb.LGBMRegressor(boosting_type='dart', num_leaves=64, max_depth=7, learning_rate=0.001, n_estimators=10000, bagging_freq = 100, feature_fraction = 0.7, reg_alpha=0.01, reg_lambda=0.01, bagging_fraction = 0.7, n_jobs = 4, metric= 'rmse')\n",
        "\n",
        "# estimator = lgb.LGBMRegressor(n_estimators=10000, learning_rate=0.05)\n",
        "\n",
        "# estimator = lgb.LGBMRegressor(boosting_type='gbdt', colsample_bytree=0.8, learning_rate=0.01, max_depth=5, metric='rmse', n_estimators=10000, n_jobs=-1, num_leaves=32, reg_alpha=0.05, reg_lambda=0.05, subsample=0.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "woTFtClOMaP3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "########## XGBoost Regressor ##########\n",
        "\n",
        "#-----#-----#----- With Default Parameters #-----#-----#-----\n",
        "\n",
        "# estimator = xgb.XGBRegressor()\n",
        "\n",
        "#-----#-----#----- Custom Parameter Run #-----#-----#-----\n",
        "\n",
        "# estimator = xgb.XGBRegressor(booster='gbtree', objective='reg:linear', eval_metric='rmse', learning_rate= 0.05, max_depth= 7, reg_alpha=0.1, reg_lambda=0.1, random_state= 42, nthread=-1, silent=True)\n",
        "\n",
        "# estimator = xgb.XGBRegressor(booster='gbtree', objective='reg:linear', eval_metric='rmse', learning_rate= 0.01, max_depth= 10, reg_alpha=0.05, reg_lambda=0.1, random_state= 42, nthread=-1, silent=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uSyZDWLwNMv7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "5f1aba24-2b4c-45c1-b522-63c067f5a3f3"
      },
      "cell_type": "code",
      "source": [
        "estimator.fit(X, y)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
              "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
              "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
              "             min_impurity_split=None, min_samples_leaf=1,\n",
              "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "             n_estimators=100, n_iter_no_change=None, presort='auto',\n",
              "             random_state=None, subsample=1.0, tol=0.0001,\n",
              "             validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "EXwjH5RrNQW4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "########## If using parameter grid for hyper-tuning ##########\n",
        "\n",
        "# print(\"Best Estimator: \",estimator.best_estimator_)\n",
        "\n",
        "# print(\"Best Parameters: \",estimator.best_params_)\n",
        "\n",
        "# print(\"Best CV Score: \",estimator.best_score_)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KvUy3LZ3N4X2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "673b34fc-1c53-4bcf-e2fd-bd0916443052"
      },
      "cell_type": "code",
      "source": [
        "########## Load Test Data ##########\n",
        "\n",
        "test_df, X_test, y_test = load(\"finalEncodedTestData.csv\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by StandardScaler.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "1tMPSdXEN-kZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "########## Prepare test label for validation ##########\n",
        "\n",
        "fullVisitorId_test_prep = test_df[['fullVisitorId','totals_transactionRevenue']]\n",
        "aggregated_df = fullVisitorId_test_prep.groupby([\"fullVisitorId\"]).sum()\n",
        "yTest = np.log1p(aggregated_df[\"totals_transactionRevenue\"].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4b-_6_yROcdu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "########## Predict the transaction value ##########\n",
        "\n",
        "prediction_test = estimator.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fD8VybJiOr5I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "########## Sum and take log of all transaction values per user ##########\n",
        "\n",
        "prediction_test[prediction_test<0] = 0.0\n",
        "prediction_inv = np.expm1(prediction_test)\n",
        "fullVisitorId_test = test_df['fullVisitorId']\n",
        "result_df = pd.concat([pd.DataFrame(fullVisitorId_test.values,columns=[\"fullVisitorId\"]),pd.DataFrame(prediction_inv,columns=[\"totals_transactionRevenue\"])],axis=1)\n",
        "aggregated_df_test = result_df.groupby([\"fullVisitorId\"]).sum()\n",
        "totals_transactionRevenue = np.log1p(aggregated_df_test[\"totals_transactionRevenue\"])\n",
        "final_df = pd.DataFrame(totals_transactionRevenue)\n",
        "pred_final = final_df[\"totals_transactionRevenue\"].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w6SqjD72O9X0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "f6a6a995-a454-4c84-f3e8-dde3310fa1b6"
      },
      "cell_type": "code",
      "source": [
        "########## Evaluation based on metrics ##########\n",
        "\n",
        "print(\"R2: \",sklm.r2_score(yTest, pred_final)) \n",
        "print(\"explained_variance_score: \",sklm.explained_variance_score(yTest, pred_final)) \n",
        "print(\"mean_absolute_error: \",sklm.mean_absolute_error(yTest, pred_final)) \n",
        "print(\"mean_squared_error: \",sklm.mean_squared_error(yTest, pred_final)) \n",
        "print(\"median_absolute_error: \",sklm.median_absolute_error(yTest, pred_final)) \n",
        "print(\"root_mean_squared_error: \",np.sqrt(sklm.mean_squared_error(yTest, pred_final)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2:  0.9997464049525271\n",
            "explained_variance_score:  0.9997490994050934\n",
            "mean_absolute_error:  0.0037290848902712887\n",
            "mean_squared_error:  0.0011561818697224141\n",
            "median_absolute_error:  2.452163117223294e-05\n",
            "root_mean_squared_error:  0.03400267444955491\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yr9XsTvQPyTr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}